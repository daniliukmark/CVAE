{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './img/skins/skins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     img  \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(file_name)\n\u001b[1;32m      7\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py:3131\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3130\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3131\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   3132\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './img/skins/skins'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     img  \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(file_name)\n\u001b[1;32m      7\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     os\u001b[39m.\u001b[39;49mremove(file_name)\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m (\u001b[39m64\u001b[39m,\u001b[39m32\u001b[39m):\n\u001b[1;32m     10\u001b[0m     os\u001b[39m.\u001b[39mremove(file_name)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './img/skins/skins'"
     ]
    }
   ],
   "source": [
    "#Some Data processing\n",
    "from PIL import Image\n",
    "for file_name in os.listdir('./img/skins'):\n",
    "    file_name = os.path.join('./img/skins', file_name)\n",
    "    try:\n",
    "        img  = Image.open(file_name)\n",
    "    except:\n",
    "        os.remove(file_name)\n",
    "    if img.size == (64,32):\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.models.Model):\n",
    "    def sampling(latent_dim = 64,**args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon_mean = 0\n",
    "        epsilon_std = 1.0\n",
    "        epsilon = keras.random_normal(shape=(keras.shape(z_mean)[0], latent_dim),\n",
    "                                  mean=epsilon_mean, stddev=epsilon_std)\n",
    "        sampled_z = z_mean + keras.exp(z_log_var * 0.5 ) * epsilon\n",
    "        return sampled_z\n",
    "\n",
    "    def __init__(self,input_shape= (64,64,3),batch_size=128, latent_dim = 64):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 4, strides=(2, 2))\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.activ1 = keras.layers.LeakyReLU()\n",
    "        self.conv2 = keras.layers.Conv2D(64, 4, strides=(2, 2))\n",
    "        self.bn3 = keras.layers.BatchNormalization()\n",
    "        self.activ2 =keras.layers.LeakyReLU()\n",
    "        self.conv3 =  keras.layers.Conv2D(128, 4, strides=(2, 2))\n",
    "        self.bn4 = keras.layers.BatchNormalization()\n",
    "        self.activ3 = keras.layers.LeakyReLU(),\n",
    "        self.pool1 = keras.layers.GlobalAveragePooling2D()\n",
    "        self.z_mean = keras.layers.Dense(latent_dim)\n",
    "        self.z_log_var = keras.layers.Dense(latent_dim)\n",
    "        \n",
    "    \n",
    "    def call(self,input):\n",
    "        conv1 = self.conv1(input)\n",
    "        bn2 = self.bn2(conv1)\n",
    "        activ1 = self.activ1(bn2)\n",
    "        conv2 = self.conv2(activ1)\n",
    "        bn3 = self.bn3(conv2)\n",
    "        activ2 = self.activ2(bn3)\n",
    "        conv3 = self.conv3(activ2)\n",
    "        bn4 = self.bn4(conv3)\n",
    "        activ3 = self.activ3(bn4)\n",
    "        pool1 = self.pool1(activ3)\n",
    "        z_mean = self.z_mean(pool1)\n",
    "        z_log_var = self.z_log_var(pool1)\n",
    "        return z_mean,z_log_var\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.models.Model):\n",
    "    def __init__(self,input_shape= (64,64,3),batch_size=128, latent_dim = 64):\n",
    "        super(Decoder,self).__init__()    \n",
    "        self.decoder_input = keras.layers.Input(shape=(latent_dim))\n",
    "        self.hidden1 = keras.layers.Dense(1024)\n",
    "        self.reshape1 = keras.layers.Reshape((4, 4, 128))\n",
    "        self.ups1 = keras.layers.UpSampling2D((2, 2), interpolation='nearest')\n",
    "        self.conv1 = keras.layers.Conv2D(64, 3, strides=1, padding='same')\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.activ1 = keras.layers.LeakyReLU()\n",
    "        self.ups2 = keras.layers.UpSampling2D((2, 2), interpolation='nearest')\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, strides=1, padding='same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.activ2 = keras.layers.LeakyReLU()\n",
    "        self.ups3 = keras.layers.UpSampling2D((2, 2), interpolation='nearest')\n",
    "        self.conv3 = keras.layers.Conv2D(16, 3, strides=1, padding='same')\n",
    "        self.bn3 = keras.layers.BatchNormalization()\n",
    "        self.activ3 = keras.layers.LeakyReLU()\n",
    "        self.ups4 = keras.layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
    "        self.conv4 = keras.layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    def call(self, input):\n",
    "        decoder_input = self.decoder_input(input)\n",
    "        hidden1 = self.hidden1(decoder_input)\n",
    "        reshape1 = self.reshape1(hidden1)\n",
    "        ups1 = self.ups1(reshape1)\n",
    "        conv1 = self.conv1(ups1)\n",
    "        bn1 = self.bn1(conv1)\n",
    "        activ1 = self.activ1(bn1)\n",
    "        ups2 = self.ups2(activ1)\n",
    "        conv2 = self.conv2(ups2)\n",
    "        bn2 = self.bn2(conv2)\n",
    "        activ2 = self.activ2(bn2)\n",
    "        ups3 = self.ups3(activ2)\n",
    "        conv3 = self.conv3(ups3)\n",
    "        bn3 = self.bn3(conv3)\n",
    "        activ3 = self.activ3(bn3)\n",
    "        ups4 = self.activ3(activ3)\n",
    "        conv4 = self.conv4(ups4)\n",
    "        return conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(keras.models.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.encoder = Encoder(latent_dim)\n",
    "    self.decoder = Decoder(latent_dim)\n",
    "  \n",
    "  @tf.function\n",
    "  def encode(self,x):\n",
    "    z_mean, z_log_var = self.encoder(x)\n",
    "    return z_mean, z_log_var\n",
    "  \n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "  \n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n",
    "  \n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  z_mean, z_log_var = model.encode(x)\n",
    "  z = model.reparameterize(z_mean, z_log_var)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, z_mean, z_log_var)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "  mean, logvar = model.encode(test_sample)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(z)\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_batch in test_dataset.take(1):\n",
    "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  start_time = time.time()\n",
    "  for train_x in train_dataset:\n",
    "    train_step(model, train_x, optimizer)\n",
    "  end_time = time.time()\n",
    "\n",
    "  loss = tf.keras.metrics.Mean()\n",
    "  for test_x in test_dataset:\n",
    "    loss(compute_loss(model, test_x))\n",
    "  elbo = -loss.result()\n",
    "  display.clear_output(wait=False)\n",
    "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n",
    "  generate_and_save_images(model, epoch, test_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
